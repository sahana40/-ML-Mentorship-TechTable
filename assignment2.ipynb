{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcYpWh7Ge17W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "In [1]:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "In [2]:\n",
        "df = pd.read_csv(\"train_AV3.csv\")\n",
        "In [3]:\n",
        "df.head()\n",
        "Out[3]:\n",
        "Loan_ID\tGender\tMarried\tDependents\tEducation\tSelf_Employed\tApplicantIncome\tCoapplicantIncome\tLoanAmount\tLoan_Amount_Term\tCredit_History\tProperty_Area\tLoan_Status\n",
        "0\tLP001002\tMale\tNo\t0\tGraduate\tNo\t5849\t0.0\tNaN\t360.0\t1.0\tUrban\tY\n",
        "1\tLP001003\tMale\tYes\t1\tGraduate\tNo\t4583\t1508.0\t128.0\t360.0\t1.0\tRural\tN\n",
        "2\tLP001005\tMale\tYes\t0\tGraduate\tYes\t3000\t0.0\t66.0\t360.0\t1.0\tUrban\tY\n",
        "3\tLP001006\tMale\tYes\t0\tNot Graduate\tNo\t2583\t2358.0\t120.0\t360.0\t1.0\tUrban\tY\n",
        "4\tLP001008\tMale\tNo\t0\tGraduate\tNo\t6000\t0.0\t141.0\t360.0\t1.0\tUrban\tY\n",
        "In [4]:\n",
        "df.columns\n",
        "Out[4]:\n",
        "Index(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
        "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
        "       'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status'],\n",
        "      dtype='object')\n",
        "In [5]:\n",
        "df.describe()\n",
        "Out[5]:\n",
        "ApplicantIncome\tCoapplicantIncome\tLoanAmount\tLoan_Amount_Term\tCredit_History\n",
        "count\t614.000000\t614.000000\t592.000000\t600.00000\t564.000000\n",
        "mean\t5403.459283\t1621.245798\t146.412162\t342.00000\t0.842199\n",
        "std\t6109.041673\t2926.248369\t85.587325\t65.12041\t0.364878\n",
        "min\t150.000000\t0.000000\t9.000000\t12.00000\t0.000000\n",
        "25%\t2877.500000\t0.000000\t100.000000\t360.00000\t1.000000\n",
        "50%\t3812.500000\t1188.500000\t128.000000\t360.00000\t1.000000\n",
        "75%\t5795.000000\t2297.250000\t168.000000\t360.00000\t1.000000\n",
        "max\t81000.000000\t41667.000000\t700.000000\t480.00000\t1.000000\n",
        "In [6]:\n",
        "df.count()\n",
        "Out[6]:\n",
        "Loan_ID              614\n",
        "Gender               601\n",
        "Married              611\n",
        "Dependents           599\n",
        "Education            614\n",
        "Self_Employed        582\n",
        "ApplicantIncome      614\n",
        "CoapplicantIncome    614\n",
        "LoanAmount           592\n",
        "Loan_Amount_Term     600\n",
        "Credit_History       564\n",
        "Property_Area        614\n",
        "Loan_Status          614\n",
        "dtype: int64\n",
        "In [7]:\n",
        "df.info()\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 614 entries, 0 to 613\n",
        "Data columns (total 13 columns):\n",
        " #   Column             Non-Null Count  Dtype  \n",
        "---  ------             --------------  -----  \n",
        " 0   Loan_ID            614 non-null    object \n",
        " 1   Gender             601 non-null    object \n",
        " 2   Married            611 non-null    object \n",
        " 3   Dependents         599 non-null    object \n",
        " 4   Education          614 non-null    object \n",
        " 5   Self_Employed      582 non-null    object \n",
        " 6   ApplicantIncome    614 non-null    int64  \n",
        " 7   CoapplicantIncome  614 non-null    float64\n",
        " 8   LoanAmount         592 non-null    float64\n",
        " 9   Loan_Amount_Term   600 non-null    float64\n",
        " 10  Credit_History     564 non-null    float64\n",
        " 11  Property_Area      614 non-null    object \n",
        " 12  Loan_Status        614 non-null    object \n",
        "dtypes: float64(4), int64(1), object(8)\n",
        "memory usage: 62.5+ KB\n",
        "In [8]:\n",
        "df.shape\n",
        "Out[8]:\n",
        "(614, 13)\n",
        "In [9]:\n",
        "null_columns=df.columns[df.isnull().any()]\n",
        "df[null_columns].isnull().sum()\n",
        "Out[9]:\n",
        "Gender              13\n",
        "Married              3\n",
        "Dependents          15\n",
        "Self_Employed       32\n",
        "LoanAmount          22\n",
        "Loan_Amount_Term    14\n",
        "Credit_History      50\n",
        "dtype: int64\n",
        "In [10]:\n",
        "gender = df[pd.notnull(df[\"Gender\"])] \n",
        "gender[\"Gender\"].value_counts()\n",
        "Out[10]:\n",
        "Male      489\n",
        "Female    112\n",
        "Name: Gender, dtype: int64\n",
        "In [11]:\n",
        "def preprocessing_train(df):\n",
        "    df[\"Gender\"].fillna(\"Male\", inplace = True)\n",
        "    df[\"Married\"].fillna( method ='ffill', inplace = True)\n",
        "    df[\"Dependents\"].fillna( method ='ffill', inplace = True)\n",
        "    df[\"Self_Employed\"].fillna( method ='ffill', inplace = True)\n",
        "    df[\"LoanAmount\"].fillna(df[\"LoanAmount\"].mean() , inplace = True)\n",
        "    df[\"Loan_Amount_Term\"].fillna(df[\"Loan_Amount_Term\"].mean() , inplace = True)\n",
        "    df[\"Credit_History\"].fillna( df[\"Credit_History\"].mean(), inplace = True)\n",
        "    \n",
        "    le_gender = LabelEncoder()\n",
        "    le_married = LabelEncoder()\n",
        "    le_education = LabelEncoder()\n",
        "    le_self_employed = LabelEncoder()\n",
        "    le_property_area = LabelEncoder()\n",
        "    le_loan_status = LabelEncoder()\n",
        "    le_dependents = LabelEncoder()\n",
        "    \n",
        "    df['Gender_n'] = le_gender.fit_transform(df['Gender'])\n",
        "    df['Married_n'] = le_married.fit_transform(df['Married'])\n",
        "    df['Dependents_n'] = le_loan_status.fit_transform(df['Dependents'])\n",
        "    df['Education_n'] = le_education.fit_transform(df['Education'])\n",
        "    df['Self_Employed_n'] = le_self_employed.fit_transform(df['Self_Employed'])\n",
        "    df['Property_Area_n'] = le_property_area.fit_transform(df['Property_Area'])\n",
        "    df['Loan_Status_n'] = le_loan_status.fit_transform(df['Loan_Status'])\n",
        "    \n",
        "    df = df.drop(columns=['Loan_ID', 'Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status','Dependents'])\n",
        "    X = df.drop(columns=[\"Loan_Status_n\"])\n",
        "    y = df[\"Loan_Status_n\"]\n",
        "    return X, y\n",
        "    \n",
        "SVM\n",
        "In [19]:\n",
        "def svm(X_train, y_train):\n",
        "    model = SVC(kernel='linear') # Linear Kernel\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "Logistic Regression\n",
        "In [20]:\n",
        "def lr(X_train, y_train):\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "K Nearest Neighbour\n",
        "In [21]:\n",
        "def knn(X_train, y_train, n_neighbors):\n",
        "    model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    model.fit(X_train,y_train)\n",
        "    return model\n",
        "Decision Tree\n",
        "In [22]:\n",
        "def decision_tree(X_train, y_train):\n",
        "    model = tree.DecisionTreeClassifier()\n",
        "    model.fit(X_train,y_train)\n",
        "    return model\n",
        "    \n",
        "Random Forest\n",
        "In [23]:\n",
        "def random_forest(X_train, y_train, n_estimators):\n",
        "    model = RandomForestRegressor(n_estimators=n_estimators)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "Predict Function\n",
        "In [24]:\n",
        "def pred(model, X_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    return y_pred\n",
        "Accuracy Function\n",
        "In [34]:\n",
        "def accuracy(y_test, y_pred):\n",
        "    print(\"Accuracy : \")\n",
        "    print(metrics.accuracy_score(y_test, y_pred.round()))\n",
        "    print()\n",
        "    print(\"###############################################\")\n",
        "    print()\n",
        "    print(\"Confusion Matrix\")\n",
        "    print(confusion_matrix(y_test,y_pred.round()))\n",
        "    print()\n",
        "    print(\"###############################################\")\n",
        "    print()\n",
        "    print(\"Classification Report\")\n",
        "    print(classification_report(y_test,y_pred.round()))\n",
        " \n",
        "Error Function\n",
        "In [26]:\n",
        "def error(y_test, y_pred):\n",
        "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
        "    print('Mean Squared Ewrror:', metrics.mean_squared_error(y_test, y_pred))\n",
        "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "Seaching optimal k\n",
        "In [27]:\n",
        "def plot_for_k(X, y):\n",
        "    \n",
        "    accuracy_rate = []\n",
        "    for i in range(1,40):\n",
        "        knn = KNeighborsClassifier(n_neighbors=i)\n",
        "        score=cross_val_score(knn,X,y,cv=10)\n",
        "        accuracy_rate.append(score.mean())\n",
        "        \n",
        "    error_rate = []\n",
        "    for i in range(1,40):\n",
        "        knn = KNeighborsClassifier(n_neighbors=i)\n",
        "        knn.fit(X_train,y_train)\n",
        "        pred_i = knn.predict(X_test)\n",
        "        error_rate.append(np.mean(pred_i != y_test))\n",
        "        \n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(range(1,40),accuracy_rate,color='blue', linestyle='dashed', marker='o',\n",
        "             markerfacecolor='red', markersize=10)\n",
        "    plt.title('Error Rate vs. K Value')\n",
        "    plt.xlabel('K')\n",
        "    plt.ylabel('Error Rate')\n",
        "    \n",
        "Testing k\n",
        "In [28]:\n",
        "def check_k(X_train, y_train, X_test, y_test, k):\n",
        "    # NOW WITH K=k\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train,y_train)\n",
        "    pred = knn.predict(X_test)\n",
        "\n",
        "    print('WITH K=2')\n",
        "    print('\\n')\n",
        "    print(confusion_matrix(y_test,pred))\n",
        "    print('\\n')\n",
        "    print(classification_report(y_test,pred))\n",
        "Preprocessing Fn Call\n",
        "In [29]:\n",
        "X, y = preprocessing_train(df)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 70% training and 20% tes\n",
        "\n",
        "Checking Accuracy for models\n",
        "In [35]:\n",
        "#SVM\n",
        "print(\"Support Vector Machine : \")\n",
        "print()\n",
        "accuracy(y_test, y_hat_svm)\n",
        "\n",
        "#Logistic Regression\n",
        "print(\"Logistic Regression : \")\n",
        "print()\n",
        "accuracy(y_test, y_hat_lr)\n",
        "\n",
        "#K Nearest Neighbors\n",
        "print(\"K Nearest Neighbors : \")\n",
        "print()\n",
        "accuracy(y_test, y_hat_knn)\n",
        "\n",
        "#Decision Tree\n",
        "print(\"Decision Tree : \")\n",
        "print()\n",
        "accuracy(y_test, y_hat_dt)\n",
        "\n",
        "#Random Forest\n",
        "print(\"Random Forest : \")\n",
        "print()\n",
        "accuracy(y_test, y_hat_rf)\n",
        "Support Vector Machine : \n",
        "\n",
        "Accuracy : \n",
        "0.8130081300813008\n",
        "\n",
        "###############################################\n",
        "Confusion Matrix\n",
        "[[19 21]\n",
        " [ 2 81]]\n",
        "\n",
        "###############################################\n",
        "\n",
        "Classification Report\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.90      0.47      0.62        40\n",
        "           1       0.79      0.98      0.88        83\n",
        "\n",
        "    accuracy                           0.81       123\n",
        "   macro avg       0.85      0.73      0.75       123\n",
        "weighted avg       0.83      0.81      0.79       123\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Logistic Regression : \n",
        "\n",
        "Accuracy : \n",
        "0.8130081300813008\n",
        "###############################################\n",
        "\n",
        "Confusion Matrix\n",
        "[[19 21]\n",
        " [ 2 81]]\n",
        "\n",
        "###############################################\n",
        "\n",
        "Classification Report\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.90      0.47      0.62        40\n",
        "           1       0.79      0.98      0.88        83\n",
        "\n",
        "    accuracy                           0.81       123\n",
        "   macro avg       0.85      0.73      0.75       123\n",
        "weighted avg       0.83      0.81      0.79       123\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "K Nearest Neighbors : \n",
        "\n",
        "Accuracy : \n",
        "0.6910569105691057\n",
        "\n",
        "###############################################\n",
        "confusion Matrix\n",
        "[[ 4 36]\n",
        " [ 2 81]]\n",
        "\n",
        "###############################################\n",
        "\n",
        "Classification Report\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.67      0.10      0.17        40\n",
        "           1       0.69      0.98      0.81        83\n",
        "\n",
        "    accuracy                           0.69       123\n",
        "   macro avg       0.68      0.54      0.49       123\n",
        "weighted avg       0.68      0.69      0.60       123\n",
        "Decision Tree : \n",
        "\n",
        "Accuracy : \n",
        "0.7235772357723578\n",
        "\n",
        "###############################################\n",
        "\n",
        "Confusion Matrix\n",
        "[[24 16]\n",
        " [18 65]]\n",
        "\n",
        "###############################################\n",
        "\n",
        "Classification Report\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.57      0.60      0.59        40\n",
        "           1       0.80      0.78      0.79        83\n",
        "\n",
        "    accuracy                           0.72       123\n",
        "   macro avg       0.69      0.69      0.69       123\n",
        "weighted avg       0.73      0.72      0.73       123\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Random Forest : \n",
        "\n",
        "Accuracy : \n",
        "0.7904878048780488\n",
        "\n",
        "###############################################  0       0.74      0.50      0.60        40\n",
        "           1       0.79      0.92      0.85        83\n",
        "\n",
        "    accuracy                           0.78       123\n",
        "   macro avg       0.77      0.71      0.72       123\n",
        "weighted avg       0.78      0.78      0.77       123\n",
        "\n",
        "\n",
        "\n",
        "Confusion Matrix\n",
        "[[20 20]\n",
        " [ 7 76]]\n",
        "\n",
        "###############################################\n",
        "\n",
        "Classification Report\n",
        "              precision    recall  f1-score   support\n",
        "                0       0.74      0.50      0.60        40\n",
        "           1       0.79      0.92      0.85        83\n",
        "\n",
        "    accuracy                           0.78       123\n",
        "   macro avg       0.77      0.71      0.72       123\n",
        "weighted avg       0.78      0.78      0.77       123\n",
        "\n",
        "\n",
        "Checking Error\n",
        "In [37]:\n",
        "#SVM\n",
        "print(\"Support Vector Machine : \")\n",
        "print()\n",
        "error(y_test, y_hat_svm)\n",
        "\n",
        "#Logistic Regression\n",
        "print(\"Logistic Regression : \")\n",
        "print()\n",
        "error(y_test, y_hat_lr)\n",
        "\n",
        "#K Nearest Neighbors\n",
        "print(\"K Nearest Neighbors : \")\n",
        "print()\n",
        "error(y_test, y_hat_knn)\n",
        "\n",
        "#Decision Tree\n",
        "print(\"Decision Tree : \")\n",
        "print()\n",
        "error(y_test, y_hat_dt)\n",
        "\n",
        "#Random Forest\n",
        "print(\"Random Forest : \")\n",
        "print()\n",
        "error(y_test, y_hat_rf)\n",
        "Support Vector Machine : \n",
        "\n",
        "Support Vector Machine : \n",
        "\n",
        "Mean Absolute Error: 0.18699186991869918\n",
        "Mean Squared Ewrror: 0.18699186991869918\n",
        "Root Mean Squared Error: 0.4324255657551935\n",
        "Logistic Regression : \n",
        "\n",
        "Mean Absolute Error: 0.18699186991869918\n",
        "Mean Squared Ewrror: 0.18699186991869918\n",
        "Root Mean Squared Error: 0.4324255657551935\n",
        "K Nearest Neighbors : \n",
        "\n",
        "Mean Absolute Error: 0.3089430894308943\n",
        "Mean Squared Ewrror: 0.3089430894308943\n",
        "Root Mean Squared Error: 0.5558264921995841\n",
        "Decision Tree : \n",
        "\n",
        "Mean Absolute Error: 0.2764227642276423\n",
        "Mean Squared Ewrror: 0.2764227642276423\n",
        "Root Mean Squared Error: 0.5257592264788534\n",
        "Random Forest : \n",
        "\n",
        "Mean Absolute Error: 0.26666666666666666\n",
        "Mean Squared Ewrror: 0.1471951219512195\n",
        "Root Mean Squared Error: 0.3836601646655794\n",
        "So I got k =22 is most optimal\n",
        "\n",
        "Test Data\n",
        "In [38]:\n",
        "test_dataset =pd.read_csv(\"test_AV3.csv\")\n",
        "In [39]:\n",
        "test_dataset.head(5)\n",
        "Out[39]:\n",
        "Loan_ID\tGender\tMarried\tDependents\tEducation\tSelf_Employed\tApplicantIncome\tCoapplicantIncome\tLoanAmount\tLoan_Amount_Term\tCredit_History\tProperty_Area\tLoan_Status\n",
        "0\tLP001015\tMale\tYes\t0\tGraduate\tNo\t5720\t0\t110.0\t360.0\t1.0\tUrban\tY\n",
        "1\tLP001022\tMale\tYes\t1\tGraduate\tNo\t3076\t1500\t126.0\t360.0\t1.0\tUrban\tY\n",
        "2\tLP001031\tMale\tYes\t2\tGraduate\tNo\t5000\t1800\t208.0\t360.0\t1.0\tUrban\tY\n",
        "3\tLP001035\tMale\tYes\t2\tGraduate\tNo\t2340\t2546\t100.0\t360.0\tNaN\tUrban\tY\n",
        "4\tLP001051\tMale\tNo\t0\tNot Graduate\tNo\t3276\t0\t78.0\t360.0\t1.0\tUrban\tY\n",
        "In [40]:\n",
        "test_dataset.info()\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 367 entries, 0 to 366\n",
        "Data columns (total 13 columns):\n",
        " #   Column             Non-Null Count  Dtype  \n",
        "---  ------             --------------  -----  \n",
        " 0   Loan_ID            367 non-null    object \n",
        " 1   Gender             356 non-null    object \n",
        " 2   Married            367 non-null    object \n",
        " 3   Dependents         357 non-null    object \n",
        " 4   Education          367 non-null    object \n",
        " 5   Self_Employed      344 non-null    object \n",
        " 6   ApplicantIncome    367 non-null    int64  \n",
        " 7   CoapplicantIncome  367 non-null    int64  \n",
        " 8   LoanAmount         362 non-null    float64\n",
        " 9   Loan_Amount_Term   361 non-null    float64\n",
        " 10  Credit_History     338 non-null    float64\n",
        " 11  Property_Area      367 non-null    object \n",
        " 12  Loan_Status        367 non-null    object \n",
        "dtypes: float64(3), int64(2), object(8)\n",
        "memory usage: 37.4+ KB\n",
        "In [41]:\n",
        "test_dataset.shape\n",
        "Out[41]:\n",
        "(367, 13)\n",
        "In [42]:\n",
        "def preprocessing_test(df):\n",
        "    \n",
        "    df[\"Gender\"].fillna(method=\"ffill\", inplace = True)\n",
        "    df[\"Married\"].fillna( method ='ffill', inplace = True)\n",
        "    df[\"Dependents\"].fillna( method ='ffill', inplace = True)\n",
        "    df[\"Self_Employed\"].fillna( method ='ffill', inplace = True)\n",
        "    df[\"LoanAmount\"].fillna(df[\"LoanAmount\"].mean() , inplace = True)\n",
        "    df[\"Loan_Amount_Term\"].fillna(df[\"Loan_Amount_Term\"].mean() , inplace = True)\n",
        "    df[\"Credit_History\"].fillna( df[\"Credit_History\"].mean(), inplace = True)\n",
        "    \n",
        "    le_gender = LabelEncoder()\n",
        "    le_married = LabelEncoder()\n",
        "    le_education = LabelEncoder()\n",
        "    le_self_employed = LabelEncoder()\n",
        "    le_property_area = LabelEncoder()\n",
        "    le_loan_status = LabelEncoder()\n",
        "    le_dependents = LabelEncoder()\n",
        "    \n",
        "    df['Gender_n'] = le_gender.fit_transform(df['Gender'])\n",
        "    df['Married_n'] = le_married.fit_transform(df['Married'])\n",
        "    df['Dependents_n'] = le_loan_status.fit_transform(df['Dependents'])\n",
        "    df['Education_n'] = le_education.fit_transform(df['Education'])\n",
        "    df['Self_Employed_n'] = le_self_employed.fit_transform(df['Self_Employed'])\n",
        "    df['Property_Area_n'] = le_property_area.fit_transform(df['Property_Area'])\n",
        "    df['Loan_Status_n'] = le_loan_status.fit_transform(df['Loan_Status'])\n",
        "    \n",
        "    df = df.drop(columns=[\"Loan_ID\",'Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status','Dependents'])\n",
        "    X = df.drop(columns=[\"Loan_Status_n\"])\n",
        "    y = df[\"Loan_Status_n\"]\n",
        "    \n",
        "    return X, y\n",
        "    In [43]:\n",
        "X_testing, y_testing = preprocessing_test(test_dataset)\n",
        "In [44]:\n",
        "y_hat_test_svm = pred(svm_model, X_testing)\n",
        "y_hat_test_lr = pred(lr_model, X_testing)\n",
        "y_hat_test_knn = pred(knn_model, X_testing)\n",
        "y_hat_test_dt = pred(decision_tree_model, X_testing)\n",
        "y_hat_test_rf = pred(random_forest_model, X_testing)\n",
        "In [45]:\n",
        "#SVM\n",
        "print(\"Support Vector Machinet : \")\n",
        "accuracy(y_testing, y_hat_test_svm)\n",
        "\n",
        "#Logistic Regression\n",
        "print(\"Logistic Regressiont : \")\n",
        "accuracy(y_testing, y_hat_test_lr)\n",
        "\n",
        "#K Nearest Neighbors\n",
        "print(\"K Nearest Neighborst : \")\n",
        "accuracy(y_testing, y_hat_test_knn)\n",
        "\n",
        "#Decision Tree\n",
        "print(\"Decision Treet : \")\n",
        "accuracy(y_testing, y_hat_test_dt)\n",
        "\n",
        "#Random Forest\n",
        "print(\"Random Forest : \")\n",
        "print()\n",
        "accuracy(y_testing, y_hat_test_rf)\n",
        "Support Vector Machinet : \n",
        "Accuracy : \n",
        "0.9782016348773842\n",
        "In [43]:\n",
        "X_testing, y_testing = preprocessing_test(test_dataset)\n",
        "In [44]:\n",
        "y_hat_test_svm = pred(svm_model, X_testing)\n",
        "y_hat_test_lr = pred(lr_model, X_testing)\n",
        "y_hat_test_knn = pred(knn_model, X_testing)\n",
        "y_hat_test_dt = pred(decision_tree_model, X_testing)\n",
        "y_hat_test_rf = pred(random_forest_model, X_testing)\n",
        "In [45]:\n",
        "#SVM\n",
        "print(\"Support Vector Machinet : \")\n",
        "accuracy(y_testing, y_hat_test_svm)\n",
        "\n",
        "#Logistic Regression\n",
        "print(\"Logistic Regressiont : \")\n",
        "accuracy(y_testing, y_hat_test_lr)\n",
        "\n",
        "#K Nearest Neighbors\n",
        "print(\"K Nearest Neighborst : \")\n",
        "accuracy(y_testing, y_hat_test_knn)\n",
        "\n",
        "#Decision Tree\n",
        "print(\"Decision Treet : \")\n",
        "accuracy(y_testing, y_hat_test_dt)\n",
        "\n",
        "#Random Forest\n",
        "print(\"Random Forest : \")\n",
        "print()\n",
        "accuracy(y_testing, y_hat_test_rf)\n",
        "Support Vector Machinet : \n",
        "Accuracy : \n",
        "0.9782016348773842\n",
        "In [43]:\n",
        "X_testing, y_testing = preprocessing_test(test_dataset)\n",
        "In [44]:\n",
        "y_hat_test_svm = pred(svm_model, X_testing)\n",
        "y_hat_test_lr = pred(lr_model, X_testing)\n",
        "y_hat_test_knn = pred(knn_model, X_testing)\n",
        "y_hat_test_dt = pred(decision_tree_model, X_testing)\n",
        "y_hat_test_rf = pred(random_forest_model, X_testing)\n",
        "In [45]:\n",
        "#SVM\n",
        "print(\"Support Vector Machinet : \")\n",
        "accuracy(y_testing, y_hat_test_svm)\n",
        "\n",
        "#Logistic Regression\n",
        "print(\"Logistic Regressiont : \")\n",
        "accuracy(y_testing, y_hat_test_lr)\n",
        "\n",
        "#K Nearest Neighbors\n",
        "print(\"K Nearest Neighborst : \")\n",
        "accuracy(y_testing, y_hat_test_knn)\n",
        "\n",
        "#Decision Tree\n",
        "print(\"Decision Treet : \")\n",
        "accuracy(y_testing, y_hat_test_dt)\n",
        "\n",
        "#Random Forest\n",
        "print(\"Random Forest : \")\n",
        "print()\n",
        "accuracy(y_testing, y_hat_test_rf)\n",
        "Support Vector Machinet : \n",
        "Accuracy : \n",
        "0.9782016348773842\n",
        "Confusion Matrix\n",
        "[[ 58   0]\n",
        " [  4 305]]\n",
        "\n",
        "###############################################\n",
        "\n",
        "Classification Report\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.94      1.00      0.97        58\n",
        "           1       1.00      0.99      0.99       309\n",
        "\n",
        "    accuracy                           0.99       367\n",
        "   macro avg       0.97      0.99      0.98       367\n",
        "weighted avg       0.99      0.99      0.99       367\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "K Nearest Neighborst : \n",
        "Accuracy : \n",
        "0.8328882833787466\n",
        "\n",
        "###############################################\n",
        "\n",
        "Confusion Matrix\n",
        "[[  3  55]\n",
        " [ 10 299]]\n",
        "\n",
        "###############################################\n",
        "\n",
        "Classification Report\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.23      0.05      0.08        58\n",
        "           1       0.84      0.97      0.90       309\n",
        "  accuracy                           0.82       367\n",
        "   macro avg       0.54      0.51      0.49       367\n",
        "weighted avg       0.75      0.82      0.77       367\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Decision Treet : \n",
        "Accuracy : \n",
        "0.8247138964577657\n",
        "\n",
        "###############################################\n",
        "\n",
        "Confusion Matrix\n",
        "[[ 54   4]\n",
        " [ 64 245]]\n",
        "\n",
        "###############################################\n",
        "\n",
        "Classification Report\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.46      0.93      0.61        58\n",
        "           1       0.98      0.79      0.88       309\n",
        "\n",
        "    accuracy                           0.81       367\n",
        "   macro avg       0.72      0.86      0.75       367\n",
        "weighted avg       0.90      0.81      0.84       367\n",
        "\n",
        "Random Forest : \n",
        "\n",
        "Accuracy : \n",
        "0.9264305177111717\n",
        "\n",
        "###############################################\n",
        "\n",
        "Confusion Matrix\n",
        "[[ 58   0]\n",
        " [ 27 282]]\n",
        "\n",
        "###############################################\n",
        "\n",
        "Classification Report\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.68      1.00      0.81        58\n",
        "           1       1.00      0.91      0.95       309\n",
        "\n",
        "    accuracy                           0.93       367\n",
        "   macro avg       0.84      0.96      0.88       367\n",
        "weighted avg       0.95      0.93      0.93       367\n",
        "In [47]:\n",
        "#SVM\n",
        "print(\"Support Vector Machine : \")\n",
        "print()\n",
        "error(y_testing, y_hat_test_svm)\n",
        "\n",
        "#Logistic Regression\n",
        "print(\"Logistic Regression : \")\n",
        "print()\n",
        "error(y_testing, y_hat_test_lr)\n",
        "\n",
        "#K Nearest Neighbors\n",
        "print(\"K Nearest Neighbors : \")\n",
        "print()\n",
        "error(y_testing, y_hat_test_knn)\n",
        "\n",
        "#Decision Tree\n",
        "print(\"Decision Tree : \")\n",
        "print()\n",
        "error(y_testing, y_hat_test_dt)\n",
        "\n",
        "#Random Forest\n",
        "print(\"Random Forest : \")\n",
        "print()\n",
        "error(y_testing, y_hat_test_rf)\n",
        "Support Vector Machine : \n",
        "\n",
        "Mean Absolute Error: 0.021798365122615803\n",
        "Mean Squared Ewrror: 0.021798365122615803\n",
        "Root Mean Squared Error: 0.14764269410511244\n",
        "Logistic Regression : \n",
        "\n",
        "Mean Absolute Error: 0.010899182561307902\n",
        "Mean Squared Ewrror: 0.010899182561307902\n",
        "Root Mean Squared Error: 0.10439915019437611\n",
        "K Nearest Neighbors : \n",
        "\n",
        "Mean Absolute Error: 0.1771117166212534\n",
        "Mean Squared Ewrror: 0.1771117166212534\n",
        "Root Mean Squared Error: 0.42084642878519646\n",
        "Decision Tree : \n",
        "\n",
        "Mean Absolute Error: 0.18528610354223432\n",
        "Mean Squared Ewrror: 0.18528610354223432\n",
        "Root Mean Squared Error: 0.4304487234761352\n",
        "Random Forest : \n",
        "\n",
        "Mean Absolute Error: 0.19482288828337874\n",
        "Mean Squared Ewrror: 0.06713896457765668\n",
        "Root Mean Squared Error: 0.2591118765661981\n",
        "In [ ]:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}